{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-Constants\" data-toc-modified-id=\"Imports-and-Constants-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and Constants</a></span></li><li><span><a href=\"#General-Helper-Functions\" data-toc-modified-id=\"General-Helper-Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>General Helper Functions</a></span></li><li><span><a href=\"#DHS-Helper-Functions\" data-toc-modified-id=\"DHS-Helper-Functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>DHS Helper Functions</a></span></li><li><span><a href=\"#DHS-NL\" data-toc-modified-id=\"DHS-NL-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>DHS NL</a></span></li><li><span><a href=\"#DHS-MS\" data-toc-modified-id=\"DHS-MS-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>DHS MS</a></span></li><li><span><a href=\"#LSMS-indexofdelta-MS\" data-toc-modified-id=\"LSMS-indexofdelta-MS-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>LSMS indexofdelta MS</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates activation maps for different models. Generating the activation maps should be done on a machine with a GPU. However, once the raw activation maps have been pickled, viewing them can be done on CPU-only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import heapq\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('../')\n",
    "from batchers import batcher, dataset_constants, delta_batcher\n",
    "from models.resnet_model import Hyperspectral_Resnet\n",
    "from utils.general import add_to_heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPTS_DIR = '../ckpts'\n",
    "LOGS_DIR = '../logs'\n",
    "NUM_TOP_IMGS = 8\n",
    "\n",
    "MODEL_PATHS = {\n",
    "    'incountry_resnet_ms_D': [\n",
    "        'DHSIncountry/incountryD_18preact_ms_samescaled_b64_fc001_conv001_lr0001',\n",
    "        'ckpt-40'],\n",
    "    'incountry_resnet_nl_C': [\n",
    "        'DHSIncountry/incountryC_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "        'ckpt-145'],\n",
    "    'lsms_indexofdelta_incountry_ms_D': [\n",
    "        'LSMSIndexOfDeltaIncountry/LSMSIndexOfDeltaIncountryD_bidir_18preact_ms_random_b64_fc1_conv1_lr0001',\n",
    "        'ckpt-64']\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LABEL_NAME = 'wealthpooled'\n",
    "GPU = 0\n",
    "GPU_USAGE = 0.9\n",
    "IS_TRAINING = False\n",
    "MODEL_PARAMS = {\n",
    "    'fc_reg': 5e-3,\n",
    "    'conv_reg': 5e-3,\n",
    "    'num_layers': 18,\n",
    "    'num_outputs': 1\n",
    "}\n",
    "\n",
    "TENSOR_NAMES = {\n",
    "    'scale1_img': 'resnet/scale1/scale1_img:0',  # batch_size, 112, 112,  64\n",
    "    'scale2_img': 'resnet/scale2/scale2_img:0',  # batch_size,  56,  56,  64\n",
    "    'scale3_img': 'resnet/scale3/scale3_img:0',  # batch_size,  28,  28, 128\n",
    "    'scale4_img': 'resnet/scale4/scale4_img:0',  # batch_size,  14,  14, 256\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_img_rescale(image):\n",
    "    '''\n",
    "    Args\n",
    "    - image: np.array, shape [H, W] or [H, W, 3]\n",
    "\n",
    "    Returns: img, np.array, copy of image, rescaled, then clipped at [0, 1]\n",
    "    '''\n",
    "    img = np.array(image)\n",
    "    # center images towards mean-0\n",
    "    img = img / 6\n",
    "    mean = np.mean(img)\n",
    "    img -= np.sign(mean) * min(0.9*abs(mean), abs(mean)**1.4)\n",
    "    new_mean = np.mean(img)\n",
    "\n",
    "    # scale images towards std-dev 1/6\n",
    "    std = np.std(img)\n",
    "    img = (img - new_mean) * (0.16 / std)**0.7 + new_mean\n",
    "    print('Mean_0:', mean, 'Mean_new:', new_mean, 'Std_0:', std, 'Std_new:', np.std(img))\n",
    "\n",
    "    img = np.clip(img + 0.5, a_min=0, a_max=1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_grid(imgs, size, resize=PIL.Image.NEAREST, spacing=0, color=0):\n",
    "    '''\n",
    "    Args\n",
    "    - imgs: list of list of PIL.Image, 1 sublist for each row of images\n",
    "    - size: int, width/height in pixels to reshape images to\n",
    "    - resize: PIL filter\n",
    "    - spacing: int, number of pixels between adjacent images\n",
    "    - color: int, spacing color, 0 for black, 255 for white\n",
    "\n",
    "    Returns: np.array, grid of images\n",
    "    '''\n",
    "    nrows = len(imgs)\n",
    "    ncols = len(imgs[0])\n",
    "\n",
    "    gridH = nrows * size + (nrows - 1) * spacing\n",
    "    gridW = ncols * size + (ncols - 1) * spacing\n",
    "    grid = np.ones([gridH, gridW, 3], dtype=np.uint8) * color\n",
    "\n",
    "    for r in range(nrows):\n",
    "        for c in range(ncols):\n",
    "            img = imgs[r][c]\n",
    "            if img.size != (size, size):\n",
    "                img = img.resize((size, size), resize)\n",
    "            i = r * (size + spacing)\n",
    "            j = c * (size + spacing)\n",
    "            grid[i:i+size, j:j+size, :] = np.asarray(img).reshape(size, size, -1)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DHS Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dhs_batcher(ls_bands, nl_band):\n",
    "    '''\n",
    "    Args\n",
    "    - ls_bands: one of ['rgb', 'ms', None]\n",
    "    - nl_band: one of ['merge', 'split', None]\n",
    "\n",
    "    Returns\n",
    "    - batcher: Batcher\n",
    "    '''\n",
    "    all_tfrecord_paths = np.asarray(batcher.get_tfrecord_paths('2009-17', 'all'))\n",
    "    assert len(all_tfrecord_paths) == dataset_constants.SIZES['2009-17']['all']\n",
    "\n",
    "    b = batcher.Batcher(\n",
    "        tfrecord_files=all_tfrecord_paths,\n",
    "        dataset='2009-17',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_name=LABEL_NAME,\n",
    "        num_threads=4,\n",
    "        epochs=1,\n",
    "        ls_bands=ls_bands,\n",
    "        nl_band=nl_band,\n",
    "        shuffle=False,\n",
    "        augment=False,\n",
    "        normalize=True,\n",
    "        cache=False)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batches(sess, tensors_dict_ops, tensor_name, max_nbatches=None, verbose=False):\n",
    "    '''Runs the ops in tensors_dict_ops for a fixed number of batches or until\n",
    "    reaching a tf.errors.OutOfRangeError, concatenating the runs.\n",
    "\n",
    "    Note: assumes that the dataset iterator doesn't need initialization, or is\n",
    "        already initialized.\n",
    "\n",
    "    Args\n",
    "    - sess: tf.Session\n",
    "    - tensors_dict_ops: dict, str => tf.Tensor, shape [batch_size] or [batch_size, D]\n",
    "      - keys: ['images', 'years', 'locs', tensor_name]\n",
    "    - tensor_name: str, key in TENSOR_NAMES\n",
    "    - max_nbatches: int, maximum number of batches to run the ops for,\n",
    "        set to None to run until reaching a tf.errors.OutOfRangeError\n",
    "    - verbose: bool, whether to output batch processing progress\n",
    "\n",
    "    Returns\n",
    "    - top_images_avg: dict, maps filter number (int) into list of (value, data) tuples\n",
    "        value = (mean filter activation for a particular image, negative image index)\n",
    "        data = (img, year, loc, activation map)\n",
    "    '''\n",
    "    top_images_avg = defaultdict(list)\n",
    "\n",
    "    curr_batch = 0\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        while True:\n",
    "            all_tensors = sess.run(tensors_dict_ops)\n",
    "\n",
    "            imgs = all_tensors['images']  # N, H, W, C\n",
    "            years = all_tensors['years']\n",
    "            locs = all_tensors['locs']\n",
    "            actmaps = all_tensors[tensor_name]\n",
    "\n",
    "            batch_size, _, _, num_filters = actmaps.shape\n",
    "\n",
    "            actmaps_means = np.mean(actmaps, axis=(1, 2), dtype=np.float64)  # shape [batch_size, num_filters]\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                img = imgs[i]\n",
    "                year = years[i]\n",
    "                loc = tuple(locs[i])\n",
    "                actmap = actmaps[i]  # shape [H, W, num_filters]\n",
    "                actmap_means = actmaps_means[i]  # shape [num_filters]\n",
    "\n",
    "                for f in range(num_filters):\n",
    "                    value = (actmap_means[f], -(i + curr_batch*BATCH_SIZE))\n",
    "                    data = (img, year, loc, actmap[:, :, f])\n",
    "                    add_to_heap(h=top_images_avg[f], k=NUM_TOP_IMGS, value=value, data=data)\n",
    "\n",
    "            curr_batch += 1\n",
    "            if verbose:\n",
    "                speed = curr_batch / (time.time() - start_time)\n",
    "                print(f'\\rRan {curr_batch} batches ({speed:.3f} batch/s)', end='')\n",
    "            if (max_nbatches is not None) and (curr_batch >= max_nbatches):\n",
    "                break\n",
    "            if curr_batch >= 15:\n",
    "                break\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    print()  # print a newline, since the previous print()'s don't print newlines\n",
    "    return top_images_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_act_images(ckpt_path: str, fold: str, ls_bands: str,\n",
    "                       nl_band: str, tensor_name: str):\n",
    "    '''\n",
    "    Args\n",
    "    - ckpt_path: str\n",
    "    - fold: str, one of ['A', 'B', 'C', 'D', 'E']\n",
    "    - ls_bands: str or None\n",
    "    - nl_band: str or None\n",
    "    - tensor_name: str, key of TENSOR_NAMES\n",
    "\n",
    "    Returns\n",
    "    - top_images_avg: dict, maps filter number (int) into list of (value, data) tuples\n",
    "        value = (mean filter activation for a particular image, negative image index)\n",
    "        data = (img, year, loc, activation map)\n",
    "    '''\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    print('=== Running model ===')\n",
    "    print('- ckpt:', ckpt_path)\n",
    "    print('- fold:', fold)\n",
    "    print('- ls_bands, nl_band:', ls_bands, nl_band)\n",
    "\n",
    "    init_iter, batch_op = get_dhs_batcher(ls_bands, nl_band).get_batch()\n",
    "\n",
    "    print('Building model...')\n",
    "    model = Hyperspectral_Resnet(batch_op['images'], is_training=IS_TRAINING, **MODEL_PARAMS)\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    tensors_dict_ops = {\n",
    "        'images': batch_op['images'],\n",
    "        'years': batch_op['years'],\n",
    "        'locs': batch_op['locs'],\n",
    "        tensor_name: graph.get_tensor_by_name(TENSOR_NAMES[tensor_name])\n",
    "    }\n",
    "\n",
    "    print('Creating session...')\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU)\n",
    "    config_proto = tf.ConfigProto()\n",
    "    config_proto.gpu_options.per_process_gpu_memory_fraction = GPU_USAGE\n",
    "\n",
    "    with tf.Session(config=config_proto) as sess:\n",
    "        sess.run(init_iter)\n",
    "\n",
    "        # clear the model weights, then load saved checkpoint\n",
    "        print('Loading saved ckpt...')\n",
    "        saver = tf.train.Saver(var_list=None)\n",
    "        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "        saver.restore(sess, ckpt_path)\n",
    "\n",
    "        # run the saved model\n",
    "        top_images_avg = run_batches(sess, tensors_dict_ops, tensor_name, verbose=True)\n",
    "    return top_images_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activations(imgs, actmaps, locs=None, years=None, title=None, size=4, nl=False, savedir=None):\n",
    "    '''\n",
    "    Args\n",
    "    - imgs: list of np.array, length N, each np.array has shape [H, W] or [H, W, 3]\n",
    "        - if [H, W, 3], then band order is assumed to be R, G, B\n",
    "    - actmaps: list of np.array, length N, each np.array has shape [actH, actW]\n",
    "    - locs: list of (lat, lon) tuples\n",
    "    - years: list of int\n",
    "    - title: str, figure title\n",
    "    - size: int, size of each img, in inches\n",
    "    - nl: bool, when plotting nightlights images\n",
    "    - savedir: str, path to directory to save imgs and activation maps\n",
    "    '''\n",
    "    nimgs = len(imgs)\n",
    "    assert len(actmaps) == nimgs\n",
    "\n",
    "    # make copy, so we don't modify the originals\n",
    "    np_imgs = np.array(imgs)\n",
    "    np_actmaps = np.abs(np.array(actmaps))  # activation maps aren't always after a ReLU\n",
    "\n",
    "    # sort images by mean activation in descending order\n",
    "    sorted_index = np.argsort(np.mean(np_actmaps, axis=(1, 2)))[::-1]\n",
    "    np_imgs = np_imgs[sorted_index]\n",
    "    np_actmaps = np_actmaps[sorted_index]\n",
    "\n",
    "    if locs is not None:\n",
    "        locs = np.array(locs)  # make copy\n",
    "        locs = locs[sorted_index]\n",
    "    if years is not None:\n",
    "        years = np.array(years)  # make copy\n",
    "        years = years[sorted_index]\n",
    "\n",
    "    max_act = np.percentile(np_actmaps, q=99)\n",
    "\n",
    "    fig, axs = plt.subplots(2, nimgs, figsize=[size*nimgs, size*2])\n",
    "\n",
    "    for i in range(nimgs):\n",
    "        img = smart_img_rescale(np_imgs[i])\n",
    "        actmap = np_actmaps[i]\n",
    "\n",
    "        if nl:\n",
    "            mean = np.mean(actmap)\n",
    "            std = np.std(actmap)\n",
    "            actmap_max = min(np.max(actmap), mean + 6 * std)\n",
    "            actmap_min = max(np.min(actmap), mean - 6 * std)\n",
    "            actmap = (actmap - actmap_min) / actmap_max\n",
    "            actmap = np.clip(actmap, a_min=0, a_max=1)\n",
    "        else:\n",
    "            actmap = np.clip(actmap, a_min=0, a_max=max_act) / max_act\n",
    "    \n",
    "        # origin='lower' to match lat/lon direction\n",
    "        axs[0, i].imshow(img, origin='lower', vmin=0, vmax=1)\n",
    "        axs[1, i].imshow(actmap, origin='lower', vmin=0, vmax=1,\n",
    "                         interpolation='none', cmap='gray')\n",
    "\n",
    "        axs[0, i].axis('off')\n",
    "        axs[1, i].axis('off')\n",
    "\n",
    "        ax_title = []\n",
    "        if locs is not None:\n",
    "            lat, lon = locs[i]\n",
    "            ax_title.append(f'loc: ({lat:.4f}, {lon:.4f})')\n",
    "        if years is not None:\n",
    "            year = years[i]\n",
    "            ax_title.append(f'year: {year}')\n",
    "        if len(ax_title) > 0:\n",
    "            ax_title = ' '.join(ax_title)\n",
    "            axs[0, i].set_title(ax_title)\n",
    "\n",
    "        if savedir is not None:\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            img_filename = os.path.join(savedir, f'img_{i}.png')\n",
    "            # plt.imsave(img_filename, img, vmin=0, vmax=1, format='png', origin='lower')\n",
    "            print('Saving image to', img_filename)\n",
    "            PIL.Image.fromarray((img * 255).astype(np.uint8)).transpose(PIL.Image.FLIP_TOP_BOTTOM).save(img_filename, optimize=True)\n",
    "\n",
    "            actmap_filename = os.path.join(savedir, f'actmap_{i}.png')\n",
    "            # plt.imsave(actmap_filename, actmap, vmin=0, vmax=1, format='png', origin='lower', cmap='gray')\n",
    "            print('Saving activation map to', actmap_filename)\n",
    "            PIL.Image.fromarray((actmap * 255).astype(np.uint8)).transpose(PIL.Image.FLIP_TOP_BOTTOM).save(actmap_filename, optimize=True)\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, y=1.03)\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DHS NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actmaps_pkl_path = 'dhs_incountryC_actmaps_nl.pkl'\n",
    "if not os.path.exists(actmaps_pkl_path):\n",
    "    ckpt_path = os.path.join(CKPTS_DIR, *MODEL_PATHS['incountry_resnet_nl_C'])\n",
    "    fold = 'C'\n",
    "    ls_bands = None\n",
    "    nl_band = 'split'\n",
    "    tensor_name = 'scale2_img'\n",
    "\n",
    "    top_images_avg_nl = get_max_act_images(ckpt_path, fold, ls_bands, nl_band, tensor_name)\n",
    "    with open(actmaps_pkl_path, 'wb') as f:\n",
    "        pickle.dump(top_images_avg_nl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(actmaps_pkl_path, 'rb') as f:\n",
    "    top_images_avg_nl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(len(top_images_avg_nl)):\n",
    "    imgs = []\n",
    "    locs = []\n",
    "    actmaps = []\n",
    "\n",
    "    for value, data in top_images_avg_nl[f]:\n",
    "        img, year, loc, actmap = data\n",
    "        C = 0 if year < 2012 else 1\n",
    "        img = img[:, :, C]\n",
    "        imgs.append(img)\n",
    "        locs.append(loc)\n",
    "        actmaps.append(actmap)\n",
    "\n",
    "    title = f'Filter {f}'\n",
    "    plot_activations(imgs, actmaps, locs=locs, title=title, size=2, nl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DHS MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actmaps_pkl_path = 'dhs_incountryD_actmaps_ms.pkl'\n",
    "if not os.path.exists(actmaps_pkl_path):\n",
    "    ckpt_path = os.path.join(CKPTS_DIR, *MODEL_PATHS['incountry_resnet_ms_D'])\n",
    "    fold = 'D'\n",
    "    ls_bands = 'ms'\n",
    "    nl_band = None\n",
    "    tensor_name = 'scale3_img'\n",
    "\n",
    "    top_images_avg_ms = get_max_act_images(ckpt_path, fold, ls_bands, nl_band, tensor_name)\n",
    "    with open(actmaps_pkl_path, 'wb') as f:\n",
    "        pickle.dump(top_images_avg_ms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(actmaps_pkl_path, 'rb') as f:\n",
    "    top_images_avg_ms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dhs_ms_images(top_images_avg_ms, filters_to_label=None):\n",
    "    '''\n",
    "    Args\n",
    "    - top_images_avg: dict, filter number (int) => list of (value, data) tuples\n",
    "      - value = (mean filter activation for a particular image, negative image index)\n",
    "      - data = (img, year1, year2, loc, label, pred, activation map)\n",
    "    - filters_to_label: dict, filter number (int) => filter label\n",
    "      - optional: set to None to plot activation maps for all filters\n",
    "    '''\n",
    "    for f in range(len(top_images_avg_ms)):\n",
    "        savedir = None\n",
    "        filter_label = None\n",
    "        if filters_to_label is not None:\n",
    "            if f not in filters_to_label:\n",
    "                continue\n",
    "            filter_label = filters_to_label[f]\n",
    "            savedir = os.path.join(\n",
    "                LOGS_DIR, MODEL_PATHS['incountry_resnet_ms_D'][0], 'actmaps', str(f))\n",
    "\n",
    "        imgs = []\n",
    "        years = []\n",
    "        locs = []\n",
    "        actmaps = []\n",
    "\n",
    "        for value, data in top_images_avg_ms[f]:\n",
    "            img, year, loc, actmap = data\n",
    "            img = img[:, :, [2, 1, 0]]  # convert from BGR to RGB\n",
    "            imgs.append(img)\n",
    "            years.append(year)\n",
    "            locs.append(loc)\n",
    "            actmaps.append(actmap)\n",
    "\n",
    "        title = f'Filter {f:d}'\n",
    "        if filter_label is not None:\n",
    "            title += f': {filter_label}'\n",
    "        plot_activations(imgs, actmaps, locs=locs, title=title, savedir=savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_dhs_ms_images(top_images_avg_ms, filters_to_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms_filters_to_label = {\n",
    "    2: 'urban',\n",
    "    10: 'water',\n",
    "    20: 'orange',\n",
    "    45: 'water',\n",
    "    59: 'senegal_river',\n",
    "    64: 'farmland',\n",
    "    79: 'canyons',\n",
    "    82: 'greenery',\n",
    "    102: 'greenery',\n",
    "    105: 'orange'\n",
    "}\n",
    "\n",
    "plot_dhs_ms_images(top_images_avg_ms, filters_to_label=ms_filters_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in [2, 10, 64]:\n",
    "    savedir = os.path.join(LOGS_DIR, MODEL_PATHS['incountry_resnet_ms_D'][0], 'actmaps', str(f))\n",
    "    top_row, bot_row = [], []\n",
    "    for i in range(NUM_TOP_IMGS):\n",
    "        top_row.append(PIL.Image.open(os.path.join(savedir, f'img_{i}.png')))\n",
    "        bot_row.append(PIL.Image.open(os.path.join(savedir, f'actmap_{i}.png')))\n",
    "    imgs = [top_row, bot_row]\n",
    "    grid = images_grid(imgs, size=224, spacing=5, color=255)\n",
    "    savepath = os.path.join(savedir, 'grid.png')\n",
    "    PIL.Image.fromarray(grid).save(savepath, optimize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSMS indexofdelta MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lsmsdelta_test_batcher(ls_bands, nl_band, indexofdelta=False):\n",
    "    '''\n",
    "    Args\n",
    "    - ls_bands: one of ['rgb', 'ms', None]\n",
    "    - nl_band: one of ['merge', 'split', None]\n",
    "    - indexofdelta: False for delta-of-index, True for index-of-delta\n",
    "\n",
    "    Returns\n",
    "    - batcher: DeltaBatcher\n",
    "    '''\n",
    "    delta_pairs_df = pd.read_csv('../data/lsmsdelta_pairs.csv')\n",
    "\n",
    "    if indexofdelta:\n",
    "        label_col = 'index_diff'\n",
    "    else:\n",
    "        label_col = 'index'\n",
    "\n",
    "    # split => np.array\n",
    "    tfrecord_pairs, households, labels = delta_batcher.get_lsms_tfrecord_pairs(\n",
    "        indices_dict=None,  # get all TFRecords\n",
    "        delta_pairs_df=delta_pairs_df,\n",
    "        index_cols=['tfrecords_index.x', 'tfrecords_index.y'],\n",
    "        other_cols=['x', label_col])\n",
    "    weights = households / np.sum(households) * len(households)\n",
    "\n",
    "    extra_fields = {'labels': labels, 'weights': weights}\n",
    "\n",
    "    b = delta_batcher.DeltaBatcher(\n",
    "        tfrecord_pairs=tfrecord_pairs,\n",
    "        dataset='LSMS',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_name=None,\n",
    "        num_threads=4,\n",
    "        epochs=1,\n",
    "        ls_bands=ls_bands,\n",
    "        nl_band=nl_band,\n",
    "        shuffle=False,\n",
    "        augment='none',\n",
    "        normalize=True,\n",
    "        cache=False,\n",
    "        orig_labels=None,\n",
    "        extra_fields=extra_fields)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lsmsdelta_batches(sess, tensors_dict_ops, tensor_name, max_nbatches=None, verbose=False):\n",
    "    '''Runs the ops in tensors_dict_ops for a fixed number of batches or until\n",
    "    reaching a tf.errors.OutOfRangeError, concatenating the runs.\n",
    "\n",
    "    Note: assumes that the dataset iterator doesn't need initialization, or is\n",
    "        already initialized.\n",
    "\n",
    "    Args\n",
    "    - sess: tf.Session\n",
    "    - tensors_dict_ops: dict, str => tf.Tensor, shape [batch_size] or [batch_size, D]\n",
    "      - keys: ['images', 'years1', 'years2', 'locs', tensor_name]\n",
    "    - tensor_name: str, key in TENSOR_NAMES\n",
    "    - max_nbatches: int, maximum number of batches to run the ops for,\n",
    "        set to None to run until reaching a tf.errors.OutOfRangeError\n",
    "    - verbose: bool, whether to output batch processing progress\n",
    "\n",
    "    Returns\n",
    "    - top_images_avg: dict, filter number (int) => list of (value, data) tuples\n",
    "        value = (mean filter activation for a particular image, negative image index)\n",
    "        data = (img, year1, year2, loc, label, pred, activation map)\n",
    "    '''\n",
    "    top_images_avg = defaultdict(list)\n",
    "\n",
    "    curr_batch = 0\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        while True:\n",
    "            all_tensors = sess.run(tensors_dict_ops)\n",
    "\n",
    "            imgs = all_tensors['images']  # N, H, W, C\n",
    "            years1 = all_tensors['years1']\n",
    "            years2 = all_tensors['years2']\n",
    "            locs = all_tensors['locs']\n",
    "            labels = all_tensors['labels']\n",
    "            preds = all_tensors['preds']\n",
    "            actmaps = all_tensors[tensor_name]\n",
    "\n",
    "            batch_size, _, _, num_filters = actmaps.shape\n",
    "\n",
    "            actmaps_means = np.mean(actmaps, axis=(1, 2), dtype=np.float64)  # shape [batch_size, num_filters]\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                img = imgs[i]\n",
    "                y1 = years1[i]\n",
    "                y2 = years2[i]\n",
    "                loc = tuple(locs[i])\n",
    "                label = labels[i]\n",
    "                pred = preds[i]\n",
    "                actmap = actmaps[i]  # shape [H, W, num_filters]\n",
    "                actmap_means = actmaps_means[i]  # shape [num_filters]\n",
    "\n",
    "                for f in range(num_filters):\n",
    "                    value = (actmap_means[f], -(i + curr_batch*BATCH_SIZE))\n",
    "                    data = (img, y1, y2, loc, label, pred, actmap[:, :, f])\n",
    "                    add_to_heap(h=top_images_avg[f], k=NUM_TOP_IMGS, value=value, data=data)\n",
    "\n",
    "            curr_batch += 1\n",
    "            if verbose:\n",
    "                speed = curr_batch / (time.time() - start_time)\n",
    "                print(f'\\rRan {curr_batch} batches ({speed:.3f} batch/s)', end='')\n",
    "            if (max_nbatches is not None) and (curr_batch >= max_nbatches):\n",
    "                break\n",
    "            if curr_batch >= 15:\n",
    "                break\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    print()  # print a newline, since the previous print()'s don't print newlines\n",
    "    return top_images_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lsmsdelta_max_act_images(ckpt_path: str, fold: str, ls_bands: str,\n",
    "                                 nl_band: str, tensor_name: str, indexofdelta=False):\n",
    "    '''\n",
    "    Args\n",
    "    - ckpt_path: str\n",
    "    - fold: str, one of ['A', 'B', 'C', 'D', 'E']\n",
    "    - ls_bands: str or None\n",
    "    - nl_band: str or None\n",
    "    - tensor_name: str, key of TENSOR_NAMES\n",
    "    - indexofdelta: bool\n",
    "\n",
    "    Returns\n",
    "    - top_images_avg: dict, filter number (int) => list of (value, data) tuples\n",
    "        value = (mean filter activation for a particular image, negative image index)\n",
    "        data = (img, year1, year2, loc, label, pred, activation map)\n",
    "    '''\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    print('=== Running model ===')\n",
    "    print('- ckpt:', ckpt_path)\n",
    "    print('- fold:', fold)\n",
    "    print('- ls_bands, nl_band:', ls_bands, nl_band)\n",
    "\n",
    "    batcher = get_lsmsdelta_test_batcher(ls_bands, nl_band, indexofdelta)\n",
    "    init_iter, batch_op = batcher.get_batch()\n",
    "\n",
    "    print('Building model...')\n",
    "    model = Hyperspectral_Resnet(batch_op['images'], is_training=IS_TRAINING, **MODEL_PARAMS)\n",
    "    preds = tf.squeeze(model.outputs, name='preds')\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    tensors_dict_ops = {\n",
    "        'images': batch_op['images'],\n",
    "        'years1': batch_op['years1'],\n",
    "        'years2': batch_op['years2'],\n",
    "        'locs': batch_op['locs'],\n",
    "        'labels': batch_op['labels'],\n",
    "        'preds': preds,\n",
    "        tensor_name: graph.get_tensor_by_name(TENSOR_NAMES[tensor_name]),\n",
    "    }\n",
    "    # note: these are not the cross-validated ridge-regression-tuned preds\n",
    "\n",
    "    print('Creating session...')\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU)\n",
    "    config_proto = tf.ConfigProto()\n",
    "    config_proto.gpu_options.per_process_gpu_memory_fraction = GPU_USAGE\n",
    "\n",
    "    with tf.Session(config=config_proto) as sess:\n",
    "        sess.run(init_iter)\n",
    "\n",
    "        # clear the model weights, then load saved checkpoint\n",
    "        print('Loading saved ckpt...')\n",
    "        saver = tf.train.Saver(var_list=None)\n",
    "        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "        saver.restore(sess, ckpt_path)\n",
    "\n",
    "        # run the saved model\n",
    "        top_images_avg = run_lsmsdelta_batches(sess, tensors_dict_ops, tensor_name, verbose=True)\n",
    "    return top_images_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_delta_activations(imgs, actmaps, locs=None, years=None,\n",
    "                           labels=None, preds=None,\n",
    "                           title=None, size=4, nl=False, savedir=None):\n",
    "    '''\n",
    "    Args\n",
    "    - imgs: list of (img1, img2) tuples, length N\n",
    "      - imgX: np.array, shape [H, W] or [H, W, 3]\n",
    "      - if [H, W, 3], then band order is assumed to be R, G, B\n",
    "    - actmaps: list of np.array, length N, each np.array has shape [actH, actW]\n",
    "    - locs: list of (lat, lon) tuples, length N\n",
    "    - years: list of (year1, year2) tuples, length N\n",
    "    - labels: list of float, length N\n",
    "    - preds: list of float, length N\n",
    "    - title: str, figure title\n",
    "    - size: int, size of each img, in inches\n",
    "    - nl: bool, when plotting nightlights images\n",
    "    - savedir: str, path to directory to save imgs and activation maps\n",
    "    '''\n",
    "    nimgs = len(imgs)\n",
    "    assert len(actmaps) == nimgs\n",
    "\n",
    "    # make copy, so we don't modify the originals\n",
    "    np_imgs = np.array(imgs)\n",
    "    np_actmaps = np.abs(np.array(actmaps))  # activation maps aren't always after a ReLU\n",
    "\n",
    "    # sort images by mean activation in descending order\n",
    "    sorted_index = np.argsort(np.mean(np_actmaps, axis=(1, 2)))[::-1]\n",
    "    np_imgs = np_imgs[sorted_index]\n",
    "    np_actmaps = np_actmaps[sorted_index]\n",
    "\n",
    "    if locs is not None:\n",
    "        locs = np.array(locs)[sorted_index]  # make copy\n",
    "    if years is not None:\n",
    "        years = np.array(years)[sorted_index]  # make copy\n",
    "    if labels is not None:\n",
    "        labels = np.array(labels)[sorted_index]  # make copy\n",
    "    if preds is not None:\n",
    "        preds = np.array(preds)[sorted_index]  # make copy\n",
    "\n",
    "    max_act = np.percentile(np_actmaps, q=99)\n",
    "\n",
    "    # row 1 = img1, row 2 = img2, row3 = actmap\n",
    "    fig, axs = plt.subplots(3, nimgs, figsize=[size*nimgs, size*3])\n",
    "\n",
    "    for i in range(nimgs):\n",
    "        img1 = smart_img_rescale(np_imgs[i][0])\n",
    "        img2 = smart_img_rescale(np_imgs[i][1])\n",
    "        actmap = np_actmaps[i]\n",
    "\n",
    "        if nl:\n",
    "            mean = np.mean(actmap)\n",
    "            std = np.std(actmap)\n",
    "            actmap_max = min(np.max(actmap), mean + 6 * std)\n",
    "            actmap_min = max(np.min(actmap), mean - 6 * std)\n",
    "            actmap = (actmap - actmap_min) / actmap_max\n",
    "            actmap = np.clip(actmap, a_min=0, a_max=1)\n",
    "        else:\n",
    "            actmap = np.clip(actmap, a_min=0, a_max=max_act) / max_act\n",
    "    \n",
    "        # origin='lower' to match lat/lon direction\n",
    "        axs[0, i].imshow(img1, origin='lower', vmin=0, vmax=1)\n",
    "        axs[1, i].imshow(img2, origin='lower', vmin=0, vmax=1)\n",
    "        axs[2, i].imshow(actmap, origin='lower', vmin=0, vmax=1,\n",
    "                         interpolation='none', cmap='gray')\n",
    "\n",
    "        for j in range(3):\n",
    "            axs[j, i].axis('off')\n",
    "\n",
    "        ax_title = []\n",
    "        if locs is not None:\n",
    "            lat, lon = locs[i]\n",
    "            ax_title.append(f'loc: ({lat:.4f}, {lon:.4f})')\n",
    "        if years is not None:\n",
    "            (y1, y2) = years[i]\n",
    "            ax_title.append(f'y: {y1}-{y2}')\n",
    "        if labels is not None:\n",
    "            label = labels[i]\n",
    "            ax_title.append(f'\\nlabel:{label:.2f}')\n",
    "        if preds is not None:\n",
    "            pred = preds[i]\n",
    "            ax_title.append(f'pred:{pred:.2f}')\n",
    "        if len(ax_title) > 0:\n",
    "            ax_title = ' '.join(ax_title)\n",
    "            axs[0, i].set_title(ax_title)\n",
    "\n",
    "        if savedir is not None:\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            img1_filename = os.path.join(savedir, f'img_{i}_1.png')\n",
    "            print('Saving image to', img1_filename)\n",
    "            # plt.imsave(img_filename, img, vmin=0, vmax=1, format='png', origin='lower')\n",
    "            PIL.Image.fromarray((img1 * 255).astype(np.uint8)).transpose(PIL.Image.FLIP_TOP_BOTTOM).save(img1_filename, optimize=True)\n",
    "\n",
    "            img2_filename = os.path.join(savedir, f'img_{i}_2.png')\n",
    "            print('Saving image to', img2_filename)\n",
    "            PIL.Image.fromarray((img1 * 255).astype(np.uint8)).transpose(PIL.Image.FLIP_TOP_BOTTOM).save(img2_filename, optimize=True)\n",
    "\n",
    "            actmap_filename = os.path.join(savedir, f'actmap_{i}.png')\n",
    "            print('Saving activation map to', actmap_filename)\n",
    "            # plt.imsave(actmap_filename, actmap, vmin=0, vmax=1, format='png', origin='lower', cmap='gray')\n",
    "            PIL.Image.fromarray((actmap * 255).astype(np.uint8)).transpose(PIL.Image.FLIP_TOP_BOTTOM).save(actmap_filename, optimize=True)\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, y=1.03)\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actmaps_pkl_path = 'lsms_indexofdelta_incountry_ms_D_actmaps.pkl'\n",
    "if not os.path.exists(actmaps_pkl_path):\n",
    "    ckpt_path = os.path.join(CKPTS_DIR, *MODEL_PATHS['lsms_indexofdelta_incountry_ms_D'])\n",
    "    fold = 'D'\n",
    "    ls_bands = 'ms'\n",
    "    nl_band = None\n",
    "    tensor_name = 'scale3_img'\n",
    "\n",
    "    top_images_avg_ms = get_lsmsdelta_max_act_images(\n",
    "        ckpt_path, fold, ls_bands, nl_band, tensor_name)\n",
    "    with open(actmaps_pkl_path, 'wb') as f:\n",
    "        pickle.dump(top_images_avg_ms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(actmaps_pkl_path, 'rb') as f:\n",
    "    top_images_avg_ms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lsmsdelta_images(top_images_avg_ms, filters_to_label=None):\n",
    "    '''\n",
    "    Args\n",
    "    - top_images_avg: dict, filter number (int) => list of (value, data) tuples\n",
    "      - value = (mean filter activation for a particular image, negative image index)\n",
    "      - data = (img, year1, year2, loc, label, pred, activation map)\n",
    "    - filters_to_label: dict, filter number (int) => filter label\n",
    "      - optional: set to None to plot activation maps for all filters\n",
    "    '''\n",
    "    for f in sorted(top_images_avg_ms.keys()):\n",
    "        savedir = None\n",
    "        filter_label = None\n",
    "        if filters_to_label is not None:\n",
    "            if f not in filters_to_label:\n",
    "                continue\n",
    "            filter_label = filters_to_label[f]\n",
    "            savedir = os.path.join(\n",
    "                LOGS_DIR, MODEL_PATHS['lsms_indexofdelta_incountry_ms_D'][0], 'actmaps', str(f))\n",
    "\n",
    "        imgs = []\n",
    "        years = []\n",
    "        locs = []\n",
    "        labels = []\n",
    "        preds = []\n",
    "        actmaps = []\n",
    "\n",
    "        for value, data in top_images_avg_ms[f]:\n",
    "            img, y1, y2, loc, label, pred, actmap = data\n",
    "            assert img.shape[2] % 2 == 0\n",
    "            C = int(img.shape[2] / 2)\n",
    "            img1 = img[:, :, [2, 1, 0]]  # convert from BGR to RGB\n",
    "            img2 = img[:, :, [C+2, C+1, C]]\n",
    "            imgs.append((img1, img2))\n",
    "            years.append((y1, y2))\n",
    "            locs.append(loc)\n",
    "            labels.append(label)\n",
    "            preds.append(pred)\n",
    "            actmaps.append(actmap)\n",
    "\n",
    "        title = f'Filter {f}'\n",
    "        if filter_label is not None:\n",
    "            title += f': {filter_label}'\n",
    "        plot_delta_activations(imgs, actmaps, years=years, locs=locs, labels=labels,\n",
    "                               preds=preds, title=title, savedir=savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_lsmsdelta_images(top_images_avg_ms, filters_to_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_filters_to_label = {\n",
    "    8: 'water',\n",
    "    23: 'greenery',\n",
    "    25: 'missing values',\n",
    "    59: 'urban centers',\n",
    "    84: 'negative preds',\n",
    "    86: 'purple year1',\n",
    "    87: 'negative greenery',\n",
    "    94: 'urban expansion',\n",
    "    98: 'drying up',\n",
    "    117: 'urban expansion',\n",
    "    118: 'increased image clarity in year2',\n",
    "}\n",
    "\n",
    "plot_lsmsdelta_images(top_images_avg_ms, filters_to_label=ms_filters_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete List of Filter Labels\n",
    "\n",
    "- 6: missing values in y1\n",
    "- 8: water\n",
    "- 9: missing values in y1\n",
    "- 16: missing values in y1\n",
    "- 17: missing values in y1\n",
    "- 19: missing values in y1\n",
    "- 20: water\n",
    "- 23: greenery\n",
    "- 25: missing values in y1\n",
    "- 48: missing values in y1\n",
    "- 56: water\n",
    "- 59: urban centers\n",
    "- 61: missing values in y1\n",
    "- 66: missing values in y1\n",
    "- 75: missing values in y1\n",
    "- 79: missing values in y1\n",
    "- 84: negative preds, although not necessarily negative labels\n",
    "- 86: purple y1\n",
    "- 87: negative green stuff\n",
    "- 88: positive preds on yellow stuff, although not necessarily positive labels\n",
    "- 91: water\n",
    "- 92: missing values in y1\n",
    "- 94: urban expansion (maybe?)\n",
    "- 96: missing values in y1\n",
    "- 98: drying up (maybe?)\n",
    "- 117: urban expansion\n",
    "- 118: increased clarity in y2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
